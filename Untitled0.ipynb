{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz+k4lZJ8EGTBTHMJbn40z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54eac65552604970a0e88b64f74537f9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6556a7dd6b6a4a44a56877c17367691d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                 \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   600     0             0.006       511          2.76 s/draw      0:27:34   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   600     0             0.005       1023         5.76 s/draw      0:57:28   0:00:00    \n                                                                                                                   \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                  </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   600     0             0.006       511          2.76 s/draw      0:27:34   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   600     0             0.005       1023         5.76 s/draw      0:57:28   0:00:00    \n                                                                                                                   \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "6556a7dd6b6a4a44a56877c17367691d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/performancemkt-ai/MMM/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL-nK5JILBw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4937fd-ce6d-4a4c-f7bd-3286747eccd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace bayesian_mmm_project/bayesian_mmm_project/optimize_budget.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "replace bayesian_mmm_project/bayesian_mmm_project/bayesian_mmm/__init__.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "replace bayesian_mmm_project/bayesian_mmm_project/bayesian_mmm/model_hierarchical.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "replace bayesian_mmm_project/bayesian_mmm_project/bayesian_mmm/transforms.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "replace bayesian_mmm_project/bayesian_mmm_project/README.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "/content/bayesian_mmm_project\n"
          ]
        }
      ],
      "source": [
        "# (1) 압축 풀기\n",
        "!unzip -q bayesian_mmm_project.zip -d bayesian_mmm_project\n",
        "\n",
        "# (2) 프로젝트 폴더로 이동\n",
        "%cd bayesian_mmm_project\n",
        "\n",
        "# (3) 설치\n",
        "!pip -q install \"pymc>=5\" arviz pytensor pandas numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AtOZg0X8KXFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "targets = list(Path(\".\").rglob(\"transforms.py\"))\n",
        "print(\"Found transforms.py:\", len(targets))\n",
        "for p in targets:\n",
        "    print(\" -\", p)\n",
        "\n",
        "for p in targets:\n",
        "    txt = p.read_text(encoding=\"utf-8\")\n",
        "\n",
        "    # scan import 추가\n",
        "    if \"from pytensor.scan import scan\" not in txt:\n",
        "        if \"import pytensor.tensor as pt\" in txt:\n",
        "            txt = txt.replace(\n",
        "                \"import pytensor.tensor as pt\",\n",
        "                \"import pytensor.tensor as pt\\nfrom pytensor.scan import scan\"\n",
        "            )\n",
        "        else:\n",
        "            txt = \"from pytensor.scan import scan\\n\" + txt\n",
        "\n",
        "    # pt.scan -> scan\n",
        "    txt = txt.replace(\"pt.scan\", \"scan\")\n",
        "\n",
        "    # non_sequences=theta -> non_sequences=[theta]\n",
        "    txt = txt.replace(\"non_sequences=theta\", \"non_sequences=[theta]\")\n",
        "\n",
        "    # outputs_info dtype 불일치 수정 (float32 -> float64)\n",
        "    # x_var의 dtype에 맞추기 위해 x_var.dtype 사용\n",
        "    txt = txt.replace(\"outputs_info=pt.as_tensor_variable(0.0),\", \"outputs_info=pt.as_tensor_variable(0.0, dtype=x_var.dtype),\")\n",
        "\n",
        "    p.write_text(txt, encoding=\"utf-8\")\n",
        "    print(\"✅ patched:\", p)\n",
        "\n",
        "# 검증: pt.scan 남아있으면 실패\n",
        "bad = []\n",
        "for p in targets:\n",
        "    if \"pt.scan\" in p.read_text(encoding=\"utf-8\"):\n",
        "        bad.append(str(p))\n",
        "print(\"pt.scan remaining:\", bad)"
      ],
      "metadata": {
        "id": "nknLbxPJLK7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8ac333-091d-4843-cc3b-80bd8f5f40f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found transforms.py: 1\n",
            " - bayesian_mmm_project/bayesian_mmm/transforms.py\n",
            "✅ patched: bayesian_mmm_project/bayesian_mmm/transforms.py\n",
            "pt.scan remaining: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 재시작 후에는 다시 폴더로 이동해야 함\n",
        "%cd /content/bayesian_mmm_project\n",
        "\n",
        "# bayesian_mmm 패키지를 Python 경로에 추가하여 모듈을 찾을 수 있도록 합니다.\n",
        "import sys\n",
        "# 프로젝트 루트 디렉토리를 sys.path의 시작에 명시적으로 추가\n",
        "# 실제 bayesian_mmm 패키지가 위치한 경로로 수정\n",
        "project_root = '/content/bayesian_mmm_project/bayesian_mmm_project'\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "from bayesian_mmm.model_hierarchical import load_dataset, build_model\n",
        "\n",
        "DATA_PATH = \"/content/final_dataset.csv\"   # 업로드 위치가 /content 라는 전제\n",
        "\n",
        "data = load_dataset(DATA_PATH)\n",
        "model = build_model(data)\n",
        "\n",
        "with model:\n",
        "    idata = pm.sample(\n",
        "        draws=300,     # ✅ 일단 300/300으로 성공 확인 (성공하면 1000/1000으로 늘리기)\n",
        "        tune=300,\n",
        "        chains=2,\n",
        "        target_accept=0.9,\n",
        "        random_seed=42,\n",
        "    )\n",
        "\n",
        "print(\"✅ idata created:\", type(idata))\n",
        "print(az.summary(idata).head())"
      ],
      "metadata": {
        "id": "JbTuLH_TLTy_",
        "outputId": "ba3c702d-7f89-4d9e-af98-0619875a0f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "54eac65552604970a0e88b64f74537f9",
            "6556a7dd6b6a4a44a56877c17367691d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bayesian_mmm_project\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54eac65552604970a0e88b64f74537f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pymc.stats.convergence:The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ idata created: <class 'arviz.data.inference_data.InferenceData'>\n",
            "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
            "alpha_n   0.658  0.148   0.403    0.924      0.005    0.007     948.0   \n",
            "alpha_o   0.573  0.260   0.219    1.058      0.011    0.020     768.0   \n",
            "beta_n    2.276  0.496   1.463    3.251      0.017    0.023     925.0   \n",
            "beta_o    2.161  0.538   1.184    3.141      0.019    0.021     771.0   \n",
            "cross_no -0.121  0.138  -0.395    0.128      0.004    0.005     946.0   \n",
            "\n",
            "          ess_tail  r_hat  \n",
            "alpha_n      386.0    1.0  \n",
            "alpha_o      373.0    1.0  \n",
            "beta_n       417.0    1.0  \n",
            "beta_o       501.0    1.0  \n",
            "cross_no     525.0    1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert \"idata\" in globals(), \"❌ idata가 없습니다. 셀4(pm.sample)가 끝까지 완료됐는지 확인하세요.\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import arviz as az\n",
        "from google.colab import files\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# 날짜 컬럼명 대응\n",
        "if \"date\" in df.columns:\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "elif \"일자\" in df.columns:\n",
        "    df[\"date\"] = pd.to_datetime(df[\"일자\"])\n",
        "else:\n",
        "    raise ValueError(\"date/일자 컬럼을 찾지 못했습니다. final_dataset.csv 컬럼명을 확인해주세요.\")\n",
        "\n",
        "df = df.sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "month_idx = df[\"date\"].dt.month.values - 1\n",
        "weekday_idx = df[\"date\"].dt.dayofweek.values\n",
        "\n",
        "naver_spend = df[\"naver_spend\"].to_numpy(dtype=float)\n",
        "oy_spend    = df[\"oy_spend\"].to_numpy(dtype=float)\n",
        "\n",
        "# promo_cols 선정 로직을 변경하여 모델 빌딩 시 사용된 프로모션 컬럼 수와 일치시킵니다.\n",
        "# 'promo_'로 시작하는 컬럼만 선택하는 대신, 'promo' 문자열을 포함하는 모든 컬럼을 선택합니다.\n",
        "promo_cols = [c for c in df.columns if \"promo\" in c.lower()]\n",
        "promos = df[promo_cols].to_numpy(dtype=float) if len(promo_cols) > 0 else np.zeros((len(df), 0), dtype=float)\n",
        "\n",
        "n_scale = np.nanmax(naver_spend)\n",
        "o_scale = np.nanmax(oy_spend)\n",
        "n_scaled = np.clip(naver_spend / (n_scale + 1e-12), 0, None)\n",
        "o_scaled = np.clip(oy_spend    / (o_scale + 1e-12), 0, None)\n",
        "\n",
        "post = idata.posterior\n",
        "def flat(name):\n",
        "    x = post[name].values\n",
        "    return x.reshape(-1, *x.shape[2:])\n",
        "\n",
        "theta_n = flat(\"theta_n\")[:, None]\n",
        "theta_o = flat(\"theta_o\")[:, None]\n",
        "alpha_n = flat(\"alpha_n\")[:, None]\n",
        "alpha_o = flat(\"alpha_o\")[:, None]\n",
        "gamma_n = flat(\"gamma_n\")[:, None]\n",
        "gamma_o = flat(\"gamma_o\")[:, None]\n",
        "beta_n  = flat(\"beta_n\")[:, None]\n",
        "beta_o  = flat(\"beta_o\")[:, None]\n",
        "cross_no = flat(\"cross_no\")[:, None]\n",
        "cross_on = flat(\"cross_on\")[:, None]\n",
        "\n",
        "int_n_m = flat(\"intercept_n_month\")\n",
        "int_o_m = flat(\"intercept_o_month\")\n",
        "\n",
        "wd_n_raw = flat(\"weekday_n_raw\")\n",
        "wd_o_raw = flat(\"weekday_o_raw\")\n",
        "wd_n = wd_n_raw - wd_n_raw.mean(axis=1, keepdims=True)\n",
        "wd_o = wd_o_raw - wd_o_raw.mean(axis=1, keepdims=True)\n",
        "\n",
        "promo_n = flat(\"promo_n\") if \"promo_n\" in post else np.zeros((int_n_m.shape[0], promos.shape[1]))\n",
        "promo_o = flat(\"promo_o\") if \"promo_o\" in post else np.zeros((int_n_m.shape[0], promos.shape[1]))\n",
        "promo_spill_n = flat(\"promo_spill_n\") if \"promo_spill_n\" in post else np.zeros_like(promo_n)\n",
        "promo_spill_o = flat(\"promo_spill_o\") if \"promo_spill_o\" in post else np.zeros_like(promo_o)\n",
        "\n",
        "S = int_n_m.shape[0]\n",
        "T = len(df)\n",
        "\n",
        "def adstock_np(x, theta):\n",
        "    out = np.zeros((S, T))\n",
        "    for s in range(S):\n",
        "        carry = 0.0\n",
        "        for t in range(T):\n",
        "            carry = x[t] + theta[s,0] * carry\n",
        "            out[s,t] = carry\n",
        "    return out\n",
        "\n",
        "def hill_np(ad, alpha, gamma):\n",
        "    eps = 1e-12\n",
        "    return 1.0 / (1.0 + (alpha / (ad + eps)) ** (1.0 / gamma))\n",
        "\n",
        "ad_n = adstock_np(n_scaled, theta_n)\n",
        "ad_o = adstock_np(o_scaled, theta_o)\n",
        "sat_n = hill_np(ad_n, alpha_n, gamma_n)\n",
        "sat_o = hill_np(ad_o, alpha_o, gamma_o)\n",
        "\n",
        "base_n = int_n_m[:, month_idx] + wd_n[:, weekday_idx]\n",
        "base_o = int_o_m[:, month_idx] + wd_o[:, weekday_idx]\n",
        "\n",
        "media_n = beta_n * sat_n\n",
        "media_o = beta_o * sat_o\n",
        "\n",
        "cross_n = cross_no * sat_o\n",
        "cross_o = cross_on * sat_n\n",
        "\n",
        "if promos.shape[1] > 0:\n",
        "    promo_term_n = (promos @ (promo_n + promo_spill_n).T).T\n",
        "    promo_term_o = (promos @ (promo_o + promo_spill_o).T).T\n",
        "else:\n",
        "    promo_term_n = np.zeros((S, T))\n",
        "    promo_term_o = np.zeros((S, T))\n",
        "\n",
        "mu_n = base_n + media_n + cross_n + promo_term_n\n",
        "mu_o = base_o + media_o + cross_o + promo_term_o\n",
        "\n",
        "pred_n = np.exp(mu_n) - 1.0\n",
        "pred_o = np.exp(mu_o) - 1.0\n",
        "\n",
        "pred_n_no_media = np.exp(base_n + cross_n + promo_term_n) - 1.0\n",
        "pred_n_no_cross = np.exp(base_n + media_n + promo_term_n) - 1.0\n",
        "pred_n_no_promo = np.exp(base_n + media_n + cross_n) - 1.0\n",
        "pred_n_base_only = np.exp(base_n) - 1.0\n",
        "\n",
        "pred_o_no_media = np.exp(base_o + cross_o + promo_term_o) - 1.0\n",
        "pred_o_no_cross = np.exp(base_o + media_o + promo_term_o) - 1.0\n",
        "pred_o_no_promo = np.exp(base_o + media_o + cross_o) - 1.0\n",
        "pred_o_base_only = np.exp(base_o) - 1.0\n",
        "\n",
        "out = pd.DataFrame({\n",
        "    \"date\": df[\"date\"].dt.strftime(\"%Y-%m-%d\"),\n",
        "\n",
        "    \"naver_pred\": pred_n.mean(axis=0),\n",
        "    \"naver_base\": pred_n_base_only.mean(axis=0),\n",
        "    \"naver_media\": (pred_n - pred_n_no_media).mean(axis=0),\n",
        "    \"naver_cross_from_oy\": (pred_n - pred_n_no_cross).mean(axis=0),\n",
        "    \"naver_promo\": (pred_n - pred_n_no_promo).mean(axis=0),\n",
        "\n",
        "    \"oy_pred\": pred_o.mean(axis=0),\n",
        "    \"oy_base\": pred_o_base_only.mean(axis=0),\n",
        "    \"oy_media\": (pred_o - pred_o_no_media).mean(axis=0),\n",
        "    \"oy_cross_from_naver\": (pred_o - pred_o_no_cross).mean(axis=0),\n",
        "    \"oy_promo\": (pred_o - pred_o_no_promo).mean(axis=0),\n",
        "})\n",
        "\n",
        "out.to_csv(\"contributions_daily.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "az.summary(idata).to_csv(\"posterior_summary.csv\", encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ saved: contributions_daily.csv, posterior_summary.csv\")\n",
        "\n",
        "files.download(\"contributions_daily.csv\")\n",
        "files.download(\"posterior_summary.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "arYbbIICI_kI",
        "outputId": "fabac208-7fca-45bd-af56-9d850b8361bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ saved: contributions_daily.csv, posterior_summary.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b8b64a5f-5b75-45fc-9cd3-0e56634692ac\", \"contributions_daily.csv\", 49596)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cac447be-64f8-446d-b963-5c8e171a44c8\", \"posterior_summary.csv\", 5473)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}